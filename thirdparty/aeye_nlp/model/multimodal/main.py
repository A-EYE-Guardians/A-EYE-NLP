# main.py (í†µí•©íŒ)
import json
import os
import re
import queue
import sys
import threading
import time
from pathlib import Path

from dotenv import load_dotenv
from openai import OpenAI

from stt.hotword_detector import hotword_detector_worker
from stt.stt_action import record_and_transcribe
from tts.tts_action import handle_tts_action
from util.search_utils import google_search

from loader.processing_image import process_image
from util.image_action import handle_image_action
from loader.processing_sound import process_sound
from util.sound_action import handle_sound_action
from util.document_action import handle_document_action

# (ì˜µì…˜) reflexion pipeline ëª¨ë“ˆì´ ìˆìœ¼ë©´ ë¶ˆëŸ¬ì™€ì„œ ë¬¸ì„œ ì „ìš© ì²˜ë¦¬ì— ì“¸ ìˆ˜ ìˆìŒ
try:
    from reflextion_graph import run_reflexion_pipeline
    HAS_REFLEXION_GRAPH = True
except Exception:
    HAS_REFLEXION_GRAPH = False

# --------------- í™˜ê²½ ë³€ìˆ˜ ë° í´ë¼ì´ì–¸íŠ¸ ---------------
load_dotenv()
OPENAI_API_KEY = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=OPENAI_API_KEY) if OPENAI_API_KEY else None
if client is None:
    raise RuntimeError("OPENAI_API_KEY í™˜ê²½ë³€ìˆ˜ê°€ í•„ìš”í•©ë‹ˆë‹¤.")

# --------------- ì „ì—­ í/ìƒíƒœ ---------------
hotword_detected_queue = queue.Queue()
command_queue = queue.Queue()  # í…ìŠ¤íŠ¸ ì…ë ¥ ë“± ì¼ë°˜ ëª…ë ¹
running = True
MULTIMODAL_FILE_PATH = Path("./saved_result")
conversation_history = []
SESSION_TIMEOUT = 30
last_interaction_time = time.time()
is_active_session = False

# ì•¡ì…˜ ë¶„ë¥˜ ëª©ë¡ (ë„ˆê°€ ì •ì˜í•œ ê²ƒ ì¬ì‚¬ìš©)
IMAGE_ACTIONS = ["object_info", "text_recognition", "scan_code", "control_hw", "navigate_image"]
DOCUMENT_ACTIONS = ["document_summary", "code_extraction", "timeline_generation", "translation",
                    "qa_generation", "highlight", "compare_documents", "answer_by_document", "search_papers"]
SOUND_ACTIONS = ["audio_search", "audio_record", "audio_describe", "transcribe_audio"]

# ---------------- ë™ê¸° ê´€ë¦¬ ----------------

tts_playing = False

def tts_thread_func(text):
    global tts_playing
    tts_playing = True
    handle_tts_action(text)  # ê¸°ì¡´ ë¸”ë¡œí‚¹ í•¨ìˆ˜
    tts_playing = False

# ---------------- ìœ í‹¸ë¦¬í‹° ----------------
def push_history(role: str, content: str):
    global conversation_history, last_interaction_time
    conversation_history.append({"role": role, "content": content, "time": time.time()})
    last_interaction_time = time.time()

def safe_json_load(s: str):
    """GPTê°€ ë³´ë‚´ëŠ” JSON-ish ë¬¸ìì—´ì„ ì•ˆì „í•˜ê²Œ íŒŒì‹±í•˜ëŠ” best-effort helper."""
    if not s:
        return None
    s = s.strip()
    if s.startswith("```"):
        # code fence ì œê±°
        lines = s.splitlines()
        if len(lines) >= 3:
            s = "\n".join(lines[1:-1])
    # í”í•œ single quote ë¬¸ì œ ëŒ€ì²˜
    if s.startswith("{'") or "'action'" in s:
        s = s.replace("'", '"')
    # try to extract JSON object substring
    m = re.search(r"\{.*\}", s, re.S)
    if m:
        s = m.group(0)
    try:
        return json.loads(s)
    except Exception:
        try:
            # ë§ˆì§€ë§‰ ìˆ˜ë‹¨ìœ¼ë¡œ eval (ì œí•œëœ í™˜ê²½)
            obj = eval(s, {"__builtins__": {}}, {})
            if isinstance(obj, dict):
                return obj
        except Exception:
            return None

# ----------------- LLM ê¸°ë°˜ action ì¶”ë¡  -----------------
def infer_action(command: str) -> dict:
    """
    ê¸°ì¡´ infer_actionì„ ê±°ì˜ ê·¸ëŒ€ë¡œ ì‚¬ìš©.
    ì‚¬ìš©ì ë°œí™” -> action JSONì„ ë°˜í™˜.
    ì‹¤íŒ¨ì‹œ {'action':'reply','params':{'text':<ì›ë¬¸>}}
    """
    system_prompt = (
        "ë„ˆëŠ” AR ì•ˆê²½ì˜ AI ë¹„ì„œì•¼. "
        "ì˜¤ì…ë ¥, ì˜¤ì¸ì‹ ë“±ì„ ê³ ë ¤í•œ userì˜ ë°œí™”ë¥¼ ë¶„ì„í•´ì„œ ì ì ˆí•œ JSON actionìœ¼ë¡œ ë³€í™˜í•´. "
        "ì´ê±° ë“±ê³¼ ê°™ì€ ì¶”ìƒì  ì§€ì¹­ì´ í¬í•¨ë¼ ì™¸ë¶€ í•˜ë“œì›¨ì–´ì˜ ì…ë ¥ì´ í•„ìš”í•´ ë³´ì´ëŠ” ëª…ë ¹ì€ "
        "ì‚¬ìš´ë“œë‚˜ ì´ë¯¸ì§€ ê´€ë ¨ actionì¼ ê°€ëŠ¥ì„±ì´ ë†’ë‹¤ê³  ê°€ì •í•´."
        "ê° action: " 
        "object_info, íŠ¹ì • ê°ì²´ì— ëŒ€í•œ ì •ë³´. " 
        "text_recognition, ì´ë¯¸ì§€ ì† ê¸€ì ì¸ì‹. " 
        "scan_code, ë°”ì½”ë“œë‚˜ QR ì½”ë“œ ì½ê¸°. " 
        "control_hw, í•˜ë“œì›¨ì–´ ì œì–´. " 
        "audio_search, ì†Œë¦¬ ê¸°ë°˜ ê²€ìƒ‰. " 
        "audio_record, ë…¹ìŒ. " 
        "audio_describe, ì†Œë¦¬ í•´ì„¤. " 
        "navigate_image, ë°©í–¥ í‘œì‹œ. " 
        "answer_by_document, ë¬¸ì„œ ê¸°ë°˜ ë‹µë³€. " 
        "document_summary, ìš”ì•½. " 
        "transcribe_audio, stt. " 
        "qa_generation, ë¬¸ì œ ì¶œì œ. " 
        "highlight, ì¤‘ìš” í‘œì‹œí•  ë‚´ìš©. " 
        "compare_documents, ë¹„êµ. " 
        "translation, ë²ˆì—­. " 
        "timeline_generation, ì‹œê°„ëŒ€ ë‹µë³€. " 
        "code_extraction, ì½”ë”©í•œ ë¶€ë¶„ ì¶”ì¶œ. " 
        "search_papers, ê²€ìƒ‰. " 
        "reply, ìœ„ actionì´ ì•„ë‹Œ ëª¨ë“  ì¼ë°˜ ëŒ€í™”. "
        "ë°˜í™˜ì€ JSON í•˜ë‚˜ë§Œ, í˜•ì‹ì€ {\"action\":\"...\",\"params\":{...}}."
    )
    if client is None:
        return {"action":"reply","params":{"text":"OpenAI í‚¤ê°€ ì„¤ì •ë˜ì–´ ìˆì§€ ì•ŠìŠµë‹ˆë‹¤."}}
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[
                {"role":"system","content":system_prompt},
                {"role":"user","content":command}
            ],
            temperature=0,
            max_tokens=300
        )
        raw = resp.choices[0].message.content.strip()
        parsed = safe_json_load(raw)
        if parsed and isinstance(parsed, dict):
            return parsed
    except Exception as e:
        print(f"[GPT ERROR infer_action] {e}", file=sys.stderr)
    return {"action":"reply","params":{"text":command}}

# ----------------- Reflection ë‹¨ê³„: ì´ˆì•ˆ -> ê°œì„ ì•ˆ(ì•¡ì…˜) -----------------
def improve_action_via_reflection(user_command: str, draft_action: dict, memory_context: str = None) -> dict:
    """
    1) draft_action(JSON)ê³¼ ì›ë¬¸ user_commandë¥¼ LLMì— ì£¼ê³ 
    2) ê°œì„ ëœ action JSONì„ ë°˜í™˜í•˜ë„ë¡ ìš”ì²­(ì´ê²Œ 'ë°˜ì„±'ì˜ í•µì‹¬)
    ë°˜í™˜ê°’: dict action (fallback: draft_action)
    """
    system = (
        "ë‹¹ì‹ ì€ ìê°€ë°˜ì„±(Reflexion) ëª¨ë“ˆì…ë‹ˆë‹¤. ì‚¬ìš©ìì˜ ëª…ë ¹ê³¼ ì´ˆê¸° ì•¡ì…˜ ì´ˆì•ˆì„ ë³´ê³ , "
        "ì‹¤ì œ ì‹¤í–‰ì— ë” ì ì ˆí•œ í˜•íƒœì˜ action JSONì„ ìƒì„±í•˜ì„¸ìš”. "
        "ë°˜ë“œì‹œ JSON í•˜ë‚˜ë§Œ ë°˜í™˜í•˜ì„¸ìš”. (ì˜ˆ: {\"action\":\"document_summary\",\"params\":{\"query\":\"íŠœë§ í…ŒìŠ¤íŠ¸\"}} )"
    )
    user_msg = f"ì›ë¬¸: {user_command}\n\nì´ˆì•ˆì•¡ì…˜: {json.dumps(draft_action, ensure_ascii=False)}"
    if memory_context:
        user_msg += f"\n\nê¸°ì–µ: {memory_context}"
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":system}, {"role":"user","content":user_msg}],
            temperature=0.0,
            max_tokens=300
        )
        raw = resp.choices[0].message.content
        parsed = safe_json_load(raw)
        if parsed and isinstance(parsed, dict):
            return parsed
    except Exception as e:
        print(f"[GPT ERROR improve_action] {e}", file=sys.stderr)
    # fallback
    return draft_action

# ----------------- Action ì‹¤í–‰ê¸° -----------------
def execute_action(action: dict, user_command: str, state: dict):
    """
    action(dict) ì‹¤í–‰: ì—¬ëŸ¬ í•¸ë“¤ëŸ¬ë“¤ í˜¸ì¶œ.
    ë°˜í™˜: (result_text (str) or structured object)
    """
    if not isinstance(action, dict):
        return "[ERROR] ì•¡ì…˜ í¬ë§· ë¶ˆì¼ì¹˜"

    act_name = action.get("action", "reply")
    params = action.get("params", {}) or {}

    try:
        if act_name == "reply":
            # ê°„ë‹¨í•œ ëŒ€í™” (ê¸°ì¡´ conversation memory ì‚¬ìš©)
            # chat_with_memoryëŠ” ê¸´ í…ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•  ìˆ˜ ìˆìŒ
            res = chat_with_memory(user_command)
            return res

        if act_name in IMAGE_ACTIONS:
            # ì´ë¯¸ì§€ action: action(dict) -> process_image -> handle_image_action
            processed = process_image(action, user_command)
            # save tensor to state for possible follow-up
            state["last_image_tensor"] = processed.get("image_tensor")
            res = handle_image_action(processed, MULTIMODAL_FILE_PATH)
            return res

        if act_name in SOUND_ACTIONS:
            processed = process_sound(action, user_command)
            res = handle_sound_action(processed, MULTIMODAL_FILE_PATH)
            return res

        if act_name in DOCUMENT_ACTIONS:
            # ë¬¸ì„œ ê´€ë ¨: run_reflexion_pipeline ìš°ì„ (ìˆë‹¤ë©´), ì•„ë‹ˆë©´ document_action handler
            if HAS_REFLEXION_GRAPH and params.get("use_reflexion", True):
                final_answer, traj = run_reflexion_pipeline(user_command)
                return final_answer
            else:
                # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: handle_document_actionì˜ ì¸ì í¬ë§·ì— ë§ê²Œ ë°ì´í„° ì¶”ì¶œ
                # 'query' íŒŒë¼ë¯¸í„°ê°€ ì—†ìœ¼ë©´ user_commandë¥¼ ê¸°ë³¸ê°’ìœ¼ë¡œ ì‚¬ìš©
                query = params.get("query", user_command)
                sources = params.get("sources")
                top_k = params.get("top_k", 3)

                # handle_document_actionì— ì˜¬ë°”ë¥¸ ì¸ì ì „ë‹¬
                return handle_document_action(query, sources, top_k)

            # ê²€ìƒ‰ ì•¡ì…˜ (ì„ì˜: action 'search' í˜¹ì€ 'search_papers')
        if act_name in ("search", "search_papers"):
            q = params.get("query") or user_command
            return google_search(q, num_results=params.get("num_results", 5), sleep_sec=1)

        # fallback unknown
        return f"[ERROR] ë¯¸ì •ì˜ ì•¡ì…˜: {act_name}"

    except Exception as e:
        print(f"[EXECUTION ERROR] {e}", file=sys.stderr)
        return f"[ERROR] ì‹¤í–‰ ì¤‘ ì˜ˆì™¸: {e}"

# ----------------- ë³´ì¡°: ê¸°ì¡´ chat_with_memory (re-usable) -----------------
def chat_with_memory(user_text: str):
    global conversation_history
    conversation_history.append({"role": "user", "content": user_text})
    try:
        resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role":"system","content":"ë„ˆëŠ” ì „ë¬¸ ë¬¸ì„œ ë¶„ì„ ë° ì›¹ ê²€ìƒ‰ìš© AIì•¼."}] + conversation_history,
            temperature=0.7
        )
        reply = resp.choices[0].message.content.strip()
        conversation_history.append({"role":"assistant","content":reply})
        # TTS ìµœì í™”: ê¸¸ë©´ ìš”ì•½
        if len(reply) > 200:
            sresp = client.chat.completions.create(
                model="gpt-4o-mini",
                messages=[{"role":"system","content":"ê¸´ ë‹µë³€ì„ 200ì ë‚´ì™¸ë¡œ ìš”ì•½í•´ì¤˜."},{"role":"user","content":reply}],
                temperature=0
            )
            return sresp.choices[0].message.content.strip()
        return reply
    except Exception as e:
        print(f"[GPT ERROR chat_with_memory] {e}", file=sys.stderr)
        return "[ERROR] LLM ì˜¤ë¥˜ë¡œ ì‘ë‹µ ë¶ˆê°€"

# ----------------- ì „ì²´ íŒŒì´í”„ë¼ì¸: ë°˜ì„± ì „/í›„ í¬í•¨ -----------------
def process_with_reflection(user_input: str, state: dict):
    """
    ì „ì²´ í”Œë¡œìš°:
    1) run_reflexion_pipeline (actor -> search -> fetch -> evaluate -> reflect -> revision) ì‹œë„
       -> final_answer, traj (tool_outputs í¬í•¨)
    2) infer_action (ì´ˆì•ˆ)
    3) improve_action_via_reflection(ì´ˆì•ˆ + evidence) -> ê°œì„ ëœ ì•¡ì…˜
    4) ê²°ì •: ê°œì„ ëœ ì•¡ì…˜ì´ replyì´ë©´ final_answer ìš°ì„  ì¶œë ¥. ì•„ë‹ˆë©´ ì•¡ì…˜ ì‹¤í–‰.
    """
    global last_interaction_time
    final_answer = None
    traj = None

    # 1) Reflexion pipeline ì‹œë„ (ê°€ëŠ¥í•˜ë©´)
    if HAS_REFLEXION_GRAPH:
        try:
            # ğŸ’¡ ìˆ˜ì •ëœ ë¶€ë¶„: run_reflexion_pipelineì´ ë°˜í™˜í•˜ëŠ” ê°’ì„ ì •í™•íˆ ë°›ìŠµë‹ˆë‹¤.
            # ë§Œì•½ pipeline ë‚´ì—ì„œ ì—ëŸ¬ê°€ ë°œìƒí•˜ë©´, ì•„ë˜ except ë¸”ë¡ì—ì„œ ì¡ì•„ëƒ…ë‹ˆë‹¤.
            final_answer, traj = run_reflexion_pipeline(user_input)
        except Exception as e:
            print(f"[REFLEXION ERROR] {e}", file=sys.stderr)
            final_answer, traj = None, None

    # 2) Action ì´ˆì•ˆ
    draft = infer_action(user_input)

    # 3) evidence (tool outputs) í˜•íƒœë¡œ ì¶”ì¶œí•´ì„œ improve í•¨ìˆ˜ì— ì „ë‹¬
    evidence = None
    try:
        if traj:
            tool_list = getattr(traj, "tool_outputs", None)
            if tool_list is None and isinstance(traj, dict):
                tool_list = traj.get("tool_outputs")
            if tool_list:
                evidence = "\n\n".join(tool_list)[:3500]
    except Exception:
        evidence = None

    # 4) ê°œì„ ëœ ì•¡ì…˜ ìƒì„± (draft + evidence)
    improved = improve_action_via_reflection(user_input, draft, memory_context=evidence)

    # ì•ˆì „ì¥ì¹˜
    if not isinstance(improved, dict) or "action" not in improved:
        improved = draft

    # 5) Decision: replyì´ë©´ final_answer ë¨¼ì € ì‚¬ìš©(ìˆë‹¤ë©´)
    result = None
    if improved.get("action") == "reply":
        if final_answer:
            result = final_answer
        else:
            result = chat_with_memory(user_input)
    else:
        if evidence:
            improved.setdefault("params", {})["evidence"] = evidence
        result = execute_action(improved, user_input, state)
        if (not result or (isinstance(result, str) and not result.strip())) and final_answer:
            result = final_answer

    # 6) ê°„ë‹¨ í‰ê°€/ë°˜ì„±(ì„ íƒì )
    try:
        eval_prompt = (
            f"ì‚¬ìš©ì ëª…ë ¹: {user_input}\n\nì‹¤í–‰ëœ ì•¡ì…˜: {json.dumps(improved, ensure_ascii=False)}\n\n"
            f"ì‹¤í–‰ê²°ê³¼(ìš”ì•½): {str(result)[:2000]}\n\n"
            "ì´ ì‹¤í–‰ì˜ ë¬¸ì œì (ìˆë‹¤ë©´)ê³¼ ê°œì„ í•  ì ì„ 1-2ë¬¸ì¥ìœ¼ë¡œ ì ì–´ë¼."
        )
        eval_resp = client.chat.completions.create(
            model="gpt-4o-mini",
            messages=[{"role": "system", "content": "ë‹¹ì‹ ì€ í‰ê°€ìì…ë‹ˆë‹¤."},
                      {"role": "user", "content": eval_prompt}],
            temperature=0.0,
            max_tokens=200
        )
        evaluation = eval_resp.choices[0].message.content.strip()
    except Exception:
        evaluation = None

    # 7) TTS ë° ìƒíƒœ ì—…ë°ì´íŠ¸
    result_text = ""
    if isinstance(result, (dict, list)):
        try:
            result_text = json.dumps(result, ensure_ascii=False)[:1500]
        except Exception:
            result_text = str(result)[:1500]
    else:
        result_text = str(result) if result is not None else "[EMPTY]"

    handle_tts_action(result_text)
    # TTS ëë‚˜ê³  last_interaction_time ê°±ì‹ 
    last_interaction_time = time.time()
    result_text = str(result) if result is not None else "[EMPTY]"
    threading.Thread(target=tts_thread_func, args=(result_text,), daemon=True).start()
    push_history("assistant", result_text)
    state["last_command"] = user_input
    state["last_action"] = improved
    state["last_result"] = result_text
    return state


# ----------------- í‚¤ë³´ë“œ ë¦¬ìŠ¤ë„ˆ (stdin) -----------------
def keyboard_listener_worker():
    while running:
        try:
            line = sys.stdin.buffer.readline().decode("utf-8", errors="ignore")
            if not line:
                time.sleep(0.1)
                continue
            user_input = line.strip()
            if not user_input:
                continue
            # íŠ¹ìˆ˜ í† í° ì²˜ë¦¬
            if user_input.lower() == "as":
                command_queue.put("as_command")
            elif user_input.lower() == "sa":
                command_queue.put("sa_command")
            else:
                command_queue.put(user_input)
        except Exception as e:
            print(f"[KEYBOARD LISTENER ERROR] {e}", file=sys.stderr)
            time.sleep(0.5)

# ----------------- ë©”ì¸ ë£¨í”„ -----------------
def main():
    global running, last_interaction_time, is_active_session

    hotword_thread = threading.Thread(
        target=hotword_detector_worker,
        args=(hotword_detected_queue,),
        daemon=True)
    hotword_thread.start()

    keyboard_thread = threading.Thread(target=keyboard_listener_worker, daemon=True)
    keyboard_thread.start()

    time.sleep(1)
    print("as = txt, sa = stt: ", end='', flush=True)

    # ìƒíƒœ dict ì´ˆê¸°í™”
    state = {
        "action": "",
        "params": {},
        "command_text": "",
        "result": "",
        "last_image_tensor": None,
        "last_command": "",
        "last_result": ""
    }

    while running:
        try:
            # í•«ì›Œë“œ ê°ì§€ ê²°ê³¼ ìš°ì„  ì²˜ë¦¬
            if not hotword_detected_queue.empty():
                hotword_detected_queue.get_nowait()
                print("[DEBUG] ì›¨ì´í¬ì›Œë“œ ê°ì§€ ì‹ í˜¸ ë°›ê¸° ì§ì „")
                command_queue.put('hotword_detected')
                print("[DEBUG] ì›¨ì´í¬ì›Œë“œ ê°ì§€ ì‹ í˜¸ put ì™„ë£Œ")
                hotword_detected_queue.task_done()

            # íì—ì„œ ëª…ë ¹ ëŒ€ê¸° (is_active_sessionì— ë”°ë¼ timeout ì¡°ì ˆ)
            timeout = 0.1 #if is_active_session else None
            try:
                print("[DEBUG] command_queue.get ëŒ€ê¸°ì¤‘")
                command = command_queue.get(timeout=timeout)
            except queue.Empty:
                command = None
            print("[SYSTEM] ì›¨ì´í¬ì›Œë“œ ê°ì§€: ", {command})

            # í•«ì›Œë“œ ì²˜ë¦¬: STT â†’ ì²˜ë¦¬
            if command is None:
                continue  # í ë¹„ì–´ìˆìœ¼ë©´ ë£¨í”„ ì²˜ìŒìœ¼ë¡œ

            last_interaction_time = time.time()

            # ì‚¬ìš©ìê°€ ì…ë ¥í–ˆì„ ë•Œë§Œ last_interaction_time ê°±ì‹ 
            if command is not None and command not in ("hotword_detected", "as_command", "sa_command"):
                last_interaction_time = time.time()  # ì‚¬ìš©ìê°€ ë§í•˜ê±°ë‚˜ ì…ë ¥í–ˆì„ ë•Œë§Œ

            if command == 'hotword_detected':
                is_active_session = True
                print("[SYSTEM] STT ëª¨ë“œ ì§„ì…")
                user_text = record_and_transcribe()
                last_interaction_time = time.time()
                if user_text:
                    print(f"[SYSTEM] ê°ì§€ëœ ìŒì„± ëª…ë ¹ì–´: '{user_text}'")

                    cooldown = ["ë•¡í ë¥˜ì§€", "ë°”ì´ ë¥˜ì§€", "íƒ±ê·œë¥˜ì§€", "ë•íë¥˜ì§€", "ë°”ì´ë¥˜ì§€", "ë°”ì´ìœ ì§€", "íƒ±ê·œ ë¥˜ì§€", "ë•í ë¥˜ì§€", "ë°”ì´ ë¥˜ì§€", "ë°”ì´ ìœ ì§€", "íƒ±ê·œë£¨ì§€", "ë•íë£¨ì§€", "ë°”ì´ë£¨ì§€", "ë°”ì´ë£¨ì§€"]
                    if user_text != cooldown :
                        state = process_with_reflection(user_text, state)
                    else:
                        # ì¢…ë£Œ ë°œí™” ê°ì§€ â†’ TTS ëë‚œ í›„ pending_shutdown=True
                        state['pending_shutdown'] = True
                        # TTSë¡œ ì¢…ë£Œ ì•ˆë‚´
                        handle_tts_action("ì„¸ì…˜ì„ ì¢…ë£Œí•©ë‹ˆë‹¤.")
                        # ë§ˆì§€ë§‰ ìƒí˜¸ì‘ìš© ì‹œê°„ ê°±ì‹ : TTS ì¢…ë£Œ ì‹œì 
                        last_interaction_time = time.time()
                        print("[SYSTEM] ì¢…ë£Œ ì…ê° â†’ í•«ì›Œë“œ ëŒ€ê¸°")
                        is_active_session = False
                else:
                    print("[SYSTEM] ìŒì„± ì…ë ¥ ì—†ìŒ â†’ í•«ì›Œë“œ ëŒ€ê¸°")
                    is_active_session = False

                    # í‚¤ë³´ë“œ/í…ìŠ¤íŠ¸ ì…ë ¥ ì²˜ë¦¬

                    try:
                        command = command_queue.get(timeout=0.1)
                    except queue.Empty:
                        command = None
                    if command:
                        if command in ("as_command", "sa_command"):
                            is_active_session = True
                            print(f"[SYSTEM] {command} ëª¨ë“œ ì§„ì…")
                        else:
                            state = process_with_reflection(command, state)
                        command_queue.task_done()
            # task done safe
            try:
                command_queue.task_done()
            except Exception:
                pass

        except queue.Empty:
            # ì„¸ì…˜ íƒ€ì„ì•„ì›ƒ ì²´í¬
            if is_active_session and (
                    state.get('pending_shutdown') or (time.time() - last_interaction_time) > SESSION_TIMEOUT):
                print("[SYSTEM] ì„¸ì…˜ ì¢…ë£Œ â†’ í•«ì›Œë“œ ëŒ€ê¸°")
                is_active_session = False
                state['pending_shutdown'] = False
        except KeyboardInterrupt:
            print("[SYSTEM] KeyboardInterrupt - ì¢…ë£Œ ì¤‘...")
            running = False
            break
        except Exception as e:
            print(f"[SYSTEM ERROR] ë£¨í”„ ì˜ˆì™¸: {e}", file=sys.stderr)
            # ì„¸ì…˜ ë¦¬ì…‹
            is_active_session = False

    # Cleanup
    hotword_thread.join()
    keyboard_thread.join()

if __name__ == "__main__":
    main()
