import base64
import numpy as np
from PIL import Image
import io
from openai import OpenAI

client = OpenAI()

import base64
from mimetypes import guess_type

# Function to encode a local image into data URL
def local_image_to_data_url(image_path):
    # Guess the MIME type of the image based on the file extension
    mime_type, _ = guess_type(image_path)
    if mime_type is None:
        mime_type = 'application/octet-stream'  # Default MIME type if none is found

    # Read and encode the image file
    with open(image_path, "rb") as image_file:
        base64_encoded_data = base64.b64encode(image_file.read()).decode('utf-8')

    # Construct the data URL
    return f"data:{mime_type};base64,{base64_encoded_data}"

# Example usage
image_path = '<path_to_image>'
data_url = local_image_to_data_url(image_path)
print("Data URL:", data_url)

def ndarray_to_base64(ndarr: np.ndarray, format: str = "JPEG") -> str:
    """
    NumPy ndarray ì´ë¯¸ì§€ë¥¼ base64 ë¬¸ìì—´ë¡œ ë³€í™˜
    GPT APIì—ì„œ ì‚¬ìš©í•  ìˆ˜ ìˆëŠ” data:image/...;base64, í˜•ì‹ìœ¼ë¡œ ë°˜í™˜
    """
    # ndarray â†’ PIL Image
    image = Image.fromarray(ndarr.astype("uint8"))

    # ë©”ëª¨ë¦¬ ë²„í¼ì— ì €ì¥
    buffer = io.BytesIO()
    image.save(buffer, format=format)
    buffer.seek(0)

    # base64 ì¸ì½”ë”©
    img_str = base64.b64encode(buffer.read()).decode("utf-8")
    return f"data:image/{format.lower()};base64,{img_str}"


def analyze_image_with_gpt(ndarr: np.ndarray, prompt: str):
    """
    GPT-4o mini ë©€í‹°ëª¨ë‹¬ APIë¡œ ndarray ì´ë¯¸ì§€ë¥¼ ë¶„ì„
    """
    # ndarray â†’ base64
    img_base64 = ndarray_to_base64(ndarr)

    # API ìš”ì²­
    response = client.chat.completions.create(
        model="gpt-4o-mini",
        messages=[
            {
                "role": "user",
                "content": [
                    {"type": "text", "text": prompt},
                    {
                        "type": "image_url",
                        "image_url": {
                            "url": img_base64
                        }
                    }
                ],
            }
        ],
    )

    '''
    # MS ìµœì‹  ì˜ˆì œ(https://learn.microsoft.com/en-us/azure/ai-foundry/openai/how-to/gpt-with-vision?utm_source=chatgpt.com&tabs=rest)
    {
    "messages": [ 
        {
            "role": "system", 
            "content": "You are a helpful assistant." 
        },
        {
            "role": "user", 
            "content": [
	            {
	                "type": "text",
	                "text": "Describe this picture:"
	            },
	            {
	                "type": "image_url",
	                "image_url": {
                        "url": "<image URL>",
                        # ê·¸ëƒ¥ base64 ê¸°ë°˜ìœ¼ë¡œ í†µì¼
                        #"url": "data:image/jpeg;base64,<your_image_data>",
                        # ì €í™”ì§ˆë¡œ í†µì¼
                        "detail": "low" # auto(ì…ë ¥ í¬ê¸° ë”°ë¼ ì§€ì •), highê°€ ìˆìŒ
                    }
                } 
           ] 
        }
    ],
    "max_tokens": 100, 
    "stream": false 
}
    '''

    return response.choices[0].message["content"]


# ğŸ”¹ ì‚¬ìš© ì˜ˆì‹œ
if __name__ == "__main__":
    # ê°€ì§œ ndarray ìƒì„± (ì˜ˆ: 100x100 RGB)
    test_array = np.random.randint(0, 255, (100, 100, 3), dtype=np.uint8)

    result = analyze_image_with_gpt(test_array, "ì´ ì´ë¯¸ì§€ì— ìˆëŠ” ë¬¼ì²´ë¥¼ ì„¤ëª…í•´ì¤˜")
    print(result)
